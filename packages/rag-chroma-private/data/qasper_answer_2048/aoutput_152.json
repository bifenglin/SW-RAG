{
    "answer": "The results from the proposed strategies show that agents utilizing knowledge graphs in addition to enhanced exploration methods outperform the baseline A2C and KG-A2C. Specifically, KG-A2C-chained and KG-A2C-Explore both successfully pass the bottleneck of a score of 40, while A2C-Explore gets to the bottleneck but cannot surpass it. The knowledge graph is critical in aiding partial observability, and it is theorized to help with sample efficiency in bottleneck detection and exploration. The Go-Explore based exploration algorithm shows less difference between agents, with A2C-Explore converging more quickly but to a lower reward trajectory that fails to pass the bottleneck, whereas KG-A2C-Explore takes longer to reach a similar reward but consistently makes it through the bottleneck. The knowledge graph cell representation is identified as a better indication of what a promising state is compared to just the textual observation."
}