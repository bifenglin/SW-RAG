{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "681a5d1e",
   "metadata": {},
   "source": [
    "## Connect to template\n",
    "\n",
    "In `server.py`, set -\n",
    "```\n",
    "add_routes(app, chain_ext, path=\"/rag_ollama_multi_query\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d61a866-f91f-41ec-a840-270b0c9c895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '全国美国文学研究会的第十八届年会在哪所大学举办的？', 'context': '全国美国文学研究会\\n受秘书处委托，由我向美文会会员单位的各位代表简单汇报一下全国美国文学研究会自上届（第十七届）年会召开以来所做的工作。美文会秘书处刚刚完成了教育部社团办“关于在教育部主管社会组织中开展调研工作的通知”中要求提交的“全国美国文学研究会调研报告”（2016年11月），主要内容4项：我想就把我们提交的“调研报告”中1、2两部分中的部分内容，作为我向大会汇报的“全国美国文学研究会2014-2016年工作总结”的内容。\\n1、研究会现状和基本情况\\n美文会现有会员单位127个（不招收个人会员），包括国内主要985与211高校，以及中国社科院等科研单位和知名出版社。会长单位是南京大学，副会长单位是南京大学，中国社会科学院，北京外国语大学，北京大学，复旦大学，山东大学，秘书处设在南京大学外国语学院，秘书长、副秘书长是南京大学赵文书、何宁。美文会正式成立于1979年7月，是我国改革开放后成立最早的高校外国文学研究机构。1992年8月18日在民政部正式注册登记，获颁《中华人民共和国社会团体登记证》。美文会挂靠南京大学，财务由南京大学财务处负责，接受南京大学审计处审计，按民政部要求，每年参加年检，年检结果均为“通过”。\\n美文会秘书处聘有专职秘书，工作人员7人，包括会长，副会长，秘书长，副秘书长，常务理事等。美文会设有党小组，隶属外国语学院英语系党支部，由会长任党小组长，成员包括副会长、常务理事、副秘书长、以及参加秘书处工作的青年教师与博士生。美文会发行《全国美国文学研究会通讯》（CASAL Newsletter），现已刊出33期。美文会每年轮流召开年会和专题研讨会，迄今已经举办17届年会和11届专题研讨会。\\n2、近两年主要工作和取得的成效\\n1）上届年会。美文会第十七届年会于2014年10月24日至26日在中国人民大学苏州校区举行，由中国人民大学外国语学院承办。来自全国28个省市自治区175所高等院校、研究所、出版社的348名正式代表参加了该次年会。年会的主题是“全球化语境中的美国文学研究：理论与实践”，收到论文全文164篇，摘要273篇。会议期间，全国美国文学研究会第七届理事会召开第三次会议。会议讨论通过了增补美文会副会长、常务理事、理事、会员单位事宜。会议再次明确，两期不缴纳会费的单位视为自动退出。理事和常务理事连续两次无故不参加理事会会议自动取消理事和常务理事。\\n2、上届专题研讨会。美文会第十一届专题研讨会于2015年10月23至25日在徐州江苏师范大学举行，由江苏师大外国语学院承办。专题研讨会的主题是“美国文学中的城市”。来自全国21个省市自治区125所高等院校、研究所、出版社的88名正式代表参加了本次研讨会。收到论文全文54篇，论文摘要73篇。会议期间，美文会召开第七届理事会第三次会议，讨论通过了美文会秘书处的提议，增补何宁为理事兼任副秘书长，提请本届年会的理事会确认。\\n3、业务活动。1）继续举办“全国美国文学研究会学术成果奖”评选。美文会设立此奖项，是为了促进我国美国文学研究的繁荣与发展，每5年评选一次，迄今已经评选3次。第三届成果奖评选出“优秀专著奖”14项，在2015年10月公示，“优秀论文奖”9项，“优秀教材奖”3项，“优秀译作奖”1项。该活动不收取任何费用。2）第十七届美国戏剧研究年会。由南京师范大学外国语学院承办，2015年7月21-22日在南京举办，主题是“20-21世纪之交美国戏剧研究”。\\n4、年检情况。美文会接受业务主管单位教育部的业务指导和社团管理机关民政部社团的监督管理，执行《民间非营利组织会计制度》，接受南京大学财务处、审计处的管理和督查，接受“江苏兴瑞会计师事务所有限公司”财务审计，结果报教育部、民政部。2015年3月进行年检，编制2015年度美文会工作报告书。8月民政部“中国社会组织网”公布年检结果：“合格”。\\n2016年11月25日晚，全国美国文学研究会召开理事会，讨论了如下事项。\\n会议申办：\\n1. 19届年会（2018，浙江大学）和第12届专题研讨会（2017，河海大学），主题尚没有最终确定。\\n2. 哈尔滨工业大学申办第20届年会（2020）\\n新申请理事单位：\\n1. 中国矿业大学，推荐王丽明副教授担任理事\\n2. 哈尔滨工业大学，推荐刘克东院长任理事\\n3. 南京大学，推荐何宁（美文会副秘书长）任理事\\n会员单位变更：\\n1. 解放军国际关系学院按照相关要求退出全国美国文学研究会，因此不再常务理事单位，方成教授退出常务理事\\n2. 对外经贸大学英语学院英美文学研究所长金冰接替孙建秋担任理事\\n3. 中央民族大学外国语学院朱小琳接替郭英剑担任理事\\n4. 厦门理工大学张跃军担任理事（原为中南大学常务理事）\\n5. 上海外语教育出版社孙静接替汪义群担任理事\\n6. 黑龙江大学推荐徐文培为常务理事\\n美国族裔文学研究：空间拓展与界域重绘\\n全国美国文学研究会第十八届年会（2016）纪要\\n2016年11月25日至28日，全国美国文学研究会第十八届年会在厦门大学举行。本届年会由厦门大学外文学院承办，来自全国各地180余所高等院校、研究所、出版社的296位正式代表参加了会议。大会组委会共收到论文全文127篇、摘要371篇，与会代表围绕大会主题“美国族裔文学研究：空间拓展与界域重绘”（Ethnic Studies in US: Extending Interspace and Redefining Typology）展开了广泛而深入的研讨。\\n11月25日晚，全国美国文学研究会召开常务理事和理事会，共有23位常务理事和理事出席，理事会主要讨论通过了以下议题：\\n1. 确认2017年的专题研讨会由河海大学承办，河海大学外国语学院院长蔡斌教授在闭幕式作简单介绍。\\n2. 确认2018年第十九届年会由浙江大学承办。\\n3. 因政策变化，解放军国际关系学院退出美文会，方成教授不再担任常务理事。\\n4. 增补黑龙江大学徐文培教授为常务理事。\\n5. 增补哈尔滨工业大学（刘克东教授）、北京航空航天大学（田俊武教授）、中国矿业大学（王丽明副教授）、北京联合大学（黄宗英教授）为理事单位，山东大学李保杰教授、对外经济贸易大学金冰教授（接替孙建秋教授）、中央民族大学朱小琳教授（接替郭英剑教授）、上海外语教育出版社孙静（接替汪义群）为理事。\\n6. 重新明确会员单位申请原则。美文会实行单位会议制，欢迎尚未加入协会的单位申请加入。申请方法和申请表格可以从美文会官网上下载。填写后加盖单位公章邮寄到协会秘书处。美文会秘书处收到入会申请并收到会员费之后即通报理事会并确认会员单位资格。\\n7. 重新明确理事单位申请条件。第一，理事单位必须是正常缴纳会费的会员单位；第二，原则上需有英语语言文学硕士点；第三，符合以上条件单位可以申请成为美文会理事单位并推荐合适人选担任理事。\\n8. 理事会决定，在美文会的年会和专题研讨会上评选会议优秀论文并颁发证书。其中，优秀论文仅在向会议提交的论文全文（未发表）中评选；作者所在单位须为美文会员单位，在向会议提交论文时，注明论文未经发表，并注明申请参加会议优秀论文评选；美文会常务理事以上（含）不参加申请。\\n9. 关于本次年会优秀论文评选：已向会议提交未发表论文全文的会员单位参会代表，在12月15日前，向本会秘书处提交修改后的论文申请评选，本会将在寒假组织评选，在2017年3月公布评选结果并颁发证书。\\n11月26日上午，本届年会开幕式在厦门大学科艺报告厅举行。厦门大学校长助理张建霖教授，外文学院张龙海院长，全国美国文学研究会会长朱刚教授、副会长盛宁教授、郭继德教授、杨仁敬教授、金莉教授、王守仁教授、张冲教授、申富英教授，秘书长赵文书教授及其他与会代表出席了开幕式。\\n开幕式由外文学院副院长李美华教授主持。张建霖校长助理首先代表厦门大学对来自全国各地的与会者表示热烈欢迎，并对全国美国文学研究会第十八届年会的顺利召开表示衷心祝贺。外文学院张龙海院长代表承办方致欢迎辞，向与会者介绍了厦大外文学院的人才培养、学术研究等情况，以及年会的准备情况。全国美国文学研究会朱刚会长代表与会人员感谢厦门大学对本届年会的大力支持。朱会长简要回顾了美文会的历史和现状，并向与会代表汇报了研究会自第十七届年会以来的主要工作。最后，朱刚会长感谢全体参会代表及承办方对美文会工作的大力支持和对共同推动美国文学研究所做出的贡献，并对今后的工作提出了殷切希望。\\n本届年会共分为大会发言、小组讨论、专题研讨（panel discussion）及研究生学术论坛四个部分。11月26日上午的大会发言分别由美文会副会长金莉教授和美文会前副会长、南京大学王守仁教授主持，共有5位代表发言。\\n中国社科院外国文学研究所盛宁教授的发言题目是《对政治正确的文化批评的再审视》。盛宁教授指出，美国总统大选造成的国内民族分裂愈演愈烈，这一新国情使我国的族裔文学研究更具价值和意义。作为学者我们必须凸显自己的立场和价值判断，对少数族裔文学的审美价值要有清晰的认识。盛教授以第一代华裔作家代表汤婷婷和第二代华裔作家代表哈金为例，评析了两代作家迥异的“政治正确”书写策略。他认为，借助“政治正确”发音的族裔文学的审美价值会很快消失，我们应深刻反思非裔作家的代表――托尼・莫里森――的创作遗产。莫里森不只着眼于描写黑人苦难，更深入探索人性，将黑人作为“人性”的缩影进行刻画，这是她能够进入美国文学传统、流芳传世的重要原因。\\n复旦大学外文学院张冲教授以《超越族裔：美国族裔文学研究的几点思考》为题，探讨我国当前族裔文学研究面临的困境及出路。张冲教授指出，国内族裔文学研究仍然面临研究角度单一与模仿、研究方法过于“理论导向”、文本“碎片化”释读等问题。他建议可从“族裔文学发展流变史”、“比较族裔文学史”以及“本土裔与中国文学文化比较”等维度，重新思考我国方兴未艾的族裔文学研究，族裔文学研究应努力超越族裔而回归文学，既要思考族裔文学的“族裔性”也需关注其“文学性”。\\n在《再议作家的族裔身份问题：本质主义与自由选择》的发言中，上海外国语大学虞建华教授以斯图亚特・霍尔对“身份”的定义为出发点，对现有族裔身份的归置基准进行拷问。虞教授强调，在讨论族裔作家文化身份时，我们需聚焦常被忽视的身份的表演性和叙事性，应以社会建构理论为指导思路，走出本质主义，作家的族裔身份在全球化大势下的多元社会，应被看作一个动态、临时、杂糅的建构过程。\\n南京大学英语系朱雪峰副教授的发言《重组芝加哥：拉图尔ANT理论视阈下的<克莱伯恩公园>》以社会学家布鲁诺・拉图尔的“行动者网络理论”为视角，从“流动的城市”、“行动者网络”、“蚂蚁视角与新现实主义”三个层面审视《克莱伯恩公园》中的芝加哥城市再现。朱教授认为，此剧在美国本土政治正确风潮中的接受悖论正在于它如实近距离描述了芝加哥城市地理在互动中流变的复杂性，其政治相关性在于它没有给出一个关于芝加哥社会的明晰解释或批评，而是通过不断追踪新问题联合来重组社会，以貌似传统的新现实主义风格体现了戏剧价值。\\n厦门大学外文学院张龙海教授以《美国少数族裔文学研究在中国》为题，向大家勾勒了我国美国族裔文学研究的历史图景。张教授通过大量的文献研究和详细的数据，从研究的规模、研究队伍的状况、期刊报纸的刊登情况以及研究中出现的不平衡等方面详细探析美国少数族裔文学研究在中国的涌现和繁荣发展。\\n11月26日下午，年会设立23个分会场进行小组讨论。代表们围绕“华裔文学研究新视野”、“亚裔文学研究新视野”、“非裔文学研究新视野”、 “犹太裔文学研究新视野”、“拉美裔文学研究新视野”、“印第安裔文学研究新视野”、“族裔文学与性别研究”、“族裔文学批评理论新动向”、“少数族裔与多元文化”、“族裔文学研究中的中国视角”、“美国文学理论研究与教学”、“美国现代派文学研究”、“早期美国文学研究”等议题，对美国族裔文学展开了多层次全方位的探讨。\\n第一组（专题讨论：族裔成长小说研究）由方红、芮渝萍主持，发言人有方红（南京大学）“消声、言说与成长：《褐姑娘、褐砖房》研究”；侯金萍（华南农业大学）“华裔美国文学对成长小说的改写与创新”；芮渝萍（宁波大学）“美国华裔成长小说的特点”；谭岸青（暨南大学）“解读任碧莲《世界与小镇》的成长书写”；邹惠玲（江苏师范大学）“《飞逸》：在自省与融合之中成长”。\\n第二组（华裔文学研究新视野之一）由刘永杰、戴鸿斌主持，发言人有黄明（商丘师范学院）“严歌苓小说《扶桑》对华人形象的颠覆”；霍盛亚（北京外国语大学）“华裔美国科幻作家刘宇昆小说的“复族裔化”倾向”；刘向辉（许昌学院）“谭恩美小说《喜福会》中的文学地图与民族记忆”；刘永杰（郑州大学）“‘秘密’的真相：《蝴蝶君》主人公断袖之谊探析”；史博（华北科技学院）“解读《折纸》中爱的主题”；孙坚（陕西师范大学）“新历史主义关照下的《中国佬》”；颜碧洪（福建师范大学福清分校）“论汤亭亭《中国佬》的后现代主义书写”。\\n第三组（华裔文学研究新视野之二）由郭栖庆、金衡山主持，发言人有黄一畅（南京航空航天大学）“虚构的权威―《谁是爱尔兰人？》中的叙事伦理之辨”；季峥（重庆工商大学）“华裔美国作家入典原因探究”；金衡山（华东师范大学）“The Puzzling and Enlightening Racial Identity in Who’ s Irish？”；苏娉（中山大学）“论李翊云的非母语写作及其意义”；王芳（中央民族大学）“《无声告白》中的华裔精神生存困境探析”；王增红（厦门大学）“种族冒充、冒充叙事与混血族身份政治―威妮弗蕾德•伊顿新解”；姚红艳（武汉大学）“族群记忆、族群认同与身份建构―《接骨师之女》中的仪式书写”；周凌敏（南方医科大学）“以物为导向的本体论下的后人文主义―以《咸鱼女孩》为例”。\\n第四组（族裔文学与性别研究之一）由王玉括、田俊武主持，发言人有方小莉（四川大学）“20世纪黑人女性小说叙述策略研究”；李蕊（南京大学）“论《他们眼望上苍》中珍妮的‘生成女性’特质”；毛艳华（浙江大学）“性别‘引用’视域下《秀拉》中女性主体的初现与重构”；隋红升（浙江大学）“汉斯伯里《太阳下的葡萄干》对美国男性气质的反思”；田俊武（北京航空航天大学）“回归之路―托尼•莫里森作品中的旅行叙事”；王玉括（南京邮电大学）“黑人女性主义文学批评述评”；杨艳春（哈尔滨石油学院）“生态女性主义视域下艾丽丝•沃克作品中女性族裔身份的自我认同”；朱海峰（东北师范大学）“父权、女权、后女权―论《钢琴课》中黑人的种族出路”。\\n第五组（族裔文学与性别研究之二）由张跃军主持，发言人有董秋芳（广东农工商职业技术学院）“美国华裔女性主体身份流变―以华裔女作家英语创作为例”；刘兮颖（华中师范大学）“《卢布林的魔术师》中雅夏的身份危机与伦理选择”；杨静（广东外语外贸大学）“全球化时代的跨国婚姻：《追寻亚裔女性》”；姚丽梅（佳木斯大学）“论邝丽莎在《雪花秘扇》中的女性主义身份伦理观”；张跃军（厦门理工学院）“‘温和的女性主义’：华裔美国诗人陈美玲诗歌解读”；朱骅（上海海洋大学）“跨国主义的美国族裔文学建构”。\\n第六组（犹太裔文学研究新视野）由刘文松主持，发言人有高莉敏（上海立信会计金融学院）“《末世之城》：大屠杀的历史记忆”；胡选恩（陕西师范大学）“E.L.多克托罗《大进军》中的历史阐释模式”；孔伟（北京外国语大学）“俄国犹太人的‘应许之地’―新移民叙事中的‘发声’策略研究”；刘文松（厦门大学）“美国犹太知识分子小说探秘”；孙璐（上海外国语大学）“菲利普•罗斯《美国牧歌》中的美国民族神话及其当代启示”；张国庆（中国人民大学）“《人性的污秽》的后人道主义解读”；赵永健（浙江工商大学）“国外美国犹太戏剧研究评述”。\\n第七组（美国后现代派文学研究之一）由陈世丹、刘雪岚主持，发言人有杨仁敬（厦门大学）“略论《时间》与《达洛威夫人》的互文性”；陈世丹（中国人民大学）“后现代文学伦理学批评要义”；曾艳钰（湖南科技大学）“‘流动的爱国主义盛宴’―评美国后现代战争小说”；谷红丽（华南师范大学）“后现代主义历史叙事”；刘雪岚（社会科学院外国文学研究所）“从‘加州三部曲’看托马斯•品钦的后现代城市书写”；方凡（浙江大学）“论威廉•加斯笔下的图像与文字”；王祖友（泰州学院）“后人道主义与人道主义辨析”；陈奔（厦门大学）“美国研究背景下的后现代主义文学研究”；范小玫（厦门大学外）“德里罗小说中的全球化”。\\n第八组（美国后现代派文学研究之二）由吴泽庆、陈俊松主持，发言人有陈俊松（华东师范大学）“《地下世界》：冷战阴云的文化记忆与后现代恐怖叙事”；许希夷（南京大学）“福尔‘后9/11’小说《特别响，非常近》中的历史叙事”；史菊鸿（兰州大学）“一个城市，两幅画面――库切和詹姆斯对伦敦的不同文学再现”；吴泽庆（中央民族大学）“‘恶魔的诅咒’―欧茨的《被诅咒的》中历史书写”；姚本标（广西师范学院）“《白噪音》的‘风险社会’表征”；栾天宇（南京大学）“《赛姆勒先生的行星》中的记忆伦理与美国20世纪60年代”。\\n第九组（美国后现代派文学研究之三）由甘文平、杨纪平主持，发言人有甘文平（武汉理工大学）“米歇尔•福柯、共同体、美国越战文学”；崔永光（大连海洋大学）“世界文学史视域中的纳博科夫形象及其创作密码”；范湘萍（上海政法学院）“论‘9.11文学’结构主义叙事中的空间与政治”；林莉（东北师范大学）“论小说《恶棍来访》的空间叙事策略”；刘丹（大连外国语大学）“融合与分裂：《地下世界》中的种族冲突与文化政治”；王程辉（湖南科技大学）“纳博科夫《国王、王后和杰克》与福楼拜《包法利夫人》的互文性”；杨纪平、胡燕（北京邮电大学）“《X战警：第一战》中的族裔观”；张芳芳（上海电力学院）“论纳博科夫小说《普宁》中‘坐错车’的隐喻与流亡主题”；张蓝予（中央民族大学）“文明对话与身份认同：评《恐怖分子》的身份观念”。\\n第十组（拉美裔文学研究新视野）由李保杰、李毅峰主持，发言人有李保杰（山东大学）“当历史的重负成为过去―《古巴之王》中的‘反流亡’书写”；李毅峰（天津商业大学）“桑德拉•西斯内罗斯对女性原型形象的重新阐释”；乔玲玲（山西大同大学）“芒果街上的奇卡纳游荡者”；涂沙丽（中南民族大学）“论《石化鹿》中的奇卡娜形象”；王绵绵（浙江传媒学院）“加勒比裔美国移民女作家的空间意识及空间策略”。\\n第十一组（美国文学理论研究与教学）由郭建辉、刘春芳主持，发言人有陈�Q（中央民族大学）“论当代反本质主义文学理论的发生因缘与中国进程”；郭建辉（四川外国语大学期刊社）“英美文学教学与审美教育”；焦敏（广东外语外贸大学）“人文主义与戏剧教学”；刘春芳（山东工商学院）“美国浪漫主义文学中的平民思想”；马特（中央财经大学）“文学批评的空间转向：空间批评的新动向”；许玉军（集美大学）“东方启蒙：西方的‘东方主义’话语”。\\n第十二组（族裔文学批评理论新动向）由胡铁生、郭英剑主持，发言人有胡铁生（吉林大学）“美国少数族裔文学的演进”；郭英剑（中国人民大学）“2015美国文学：种族，还是种族问题”；洪琪（湖北第二师范学院）“美国华裔戏剧的创伤叙事”；任虎军（四川外国语大学）“性别视阈下新世纪中国的美国族裔小说研究”；王斐（集美大学）“追寻都会中的空间正义：美国非裔城市叙事嬗变初探”。\\n第十三组（美国现代派文学研究之一）由黄宗英、王跃洪主持，发言人有陈秋红（青岛大学）“亨利•詹姆斯后期小说的进化叙述”；陈喜华（湘潭大学）“菲茨杰拉德的服饰书写与爵士时代美国文化”；黄宗英（北京联合大学）“‘其城/其人，一种身份’：读威廉斯的《帕特森》”；蒋贤萍（西北师范大学）“表演的自我――再读《进入黑夜的漫长旅程》”；李晶（中南财经政法大学）“生存还是生活？：凯瑟《一个迷途的女人》的伦理选择”；陶久胜（南昌大学）“无意识的种族偏见――《上帝的儿女都有翅膀》的心理原型解读”；朱晓萍（贵州大学）“追逐无的欲望――《嘉莉妹妹》的拉康式解读”。\\n第十四组（美国现代派文学研究之二）由李建波、朴玉主持，发言人有朴玉（吉林大学）“科伦•麦凯恩在《光明这一面》中的城市创伤叙事”；王晓丹（哈尔滨师范大学）“阶层流动的幻灭：《纹身女孩》中的社会身份”；王跃洪、郝天昕（上海理工大学）“福柯凝视理论视角下的亨利•詹姆斯《德莫福夫人》研究”；薛丽（北京师范大学）“《布拉迪默传奇》中矛盾的女性意识形态”；姚学丽（安徽大学）“映射美国南方的‘隐约轮廓’――析《干旱的九月》碎片化叙事”；张金良（天津外国语大学）“哈贝马斯有效沟通视域下《奥利安娜》中的交流困境分析”；张小平（扬州大学）“旅行•幻梦•混沌――论麦卡锡小说《骏马》中的‘奇异吸引子’”。\\n第十五组（早期美国文学研究）由张和龙、金冰主持，发言人有金冰（对外经贸大学）“美国自然主义文学的进化叙事与伦理想像”；李晋（中南财经政法大学）“19世纪美国文学市场研究综述”；李敏（山东工商学院）“《红字》通奸案的法、罚与霍桑的‘疼痛’书写”；李方木（北京外国语大学）“爱的伪装：《献给爱米丽的玫瑰》中的罗曼司及其多义性”；戚涛（安徽大学）“多数暴政下的碎片――梅尔维尔的价值困惑与身份建构”；张和龙（上海外国语大学）“中国杰克•伦敦研究中的话语模式及其历史嬗变”。\\n第十六组（非裔文学研究新视野之一）由林元富主持，发言人有陈红（广东外语外贸大学）“‘所有的故事都是真的’―评怀德曼的编史元小说《法农》”；甘婷（集美大学）“第三空间理论视阈下《中间通道》的空间建构”；林元富（福建师范大学）“当代非裔美国涉奴题材小说的历史传承”；刘锦丽（湖北科技学院）“种族歧视下的身份困惑―论切斯纳特小说中的混血儿”；龙跃（湖南师范大学）“兰斯顿•休斯诗歌中的‘黑人性’”；吕春媚（大连外国语大学）“黑白的空间对峙――解读《莱尼大妈的黑臀舞》中的社会空间”；王予霞（集美大学）“美国黑人左翼文学消长的历史启示”；修树新（东北师范大学外国语学院）“论特瑞•麦克米兰小说中爱的主题”；张健然（四川外国语大学）“《他们眼望上苍》中原始性与现代性的背离与融合”。\\n第十七组（非裔文学研究新视野之二）由徐文培、杜志卿主持，发言人有杜志卿（华侨大学外国语学院）“从霍妮的精神分析理论看阿契贝笔下的伊祖鲁”；蒯冲（荆楚理工学院）“非裔美国人的身份缺失与身份认同――以《阳光下的葡萄干》为例”；李美芹（浙江工商大学）“论埃里森‘文学爵士乐’美学中表达的种族政治思想”；李云瑾（华北科技学院）“论托妮•莫里森《宣叙》的含混性”；马粉英（西北师范大学）“《最蓝的眼睛》中克劳迪娅拆解行为的后殖民叙事”；唐莹（大连外国语大学）“从‘挪亚的诅咒’到非洲主义―对罗宾逊种族书写的反思”；徐文培（黑龙江大学）“《所罗门之歌》与奴隶叙事文学”；张宏薇（东北师范大学）“莫里森早晚期两部小说中‘儿童创伤’主题的对比分析”；朱小琳（中央民族大学）“悲莫悲兮伤永逝：以墓志为叙事策略的《宠儿》新解”。\\n第十八组（亚裔文学研究新视野）由谷红丽、李汝成主持，发言人有李青霜（南京审计大学）“论戏剧《耻辱》中的穆斯林文化定势”；刘喜波（齐齐哈尔大学）“列斐伏尔的身体空间理论下的《灿烂千阳》解读”；李东风（盐城师范学院）“美国印度裔离散文学中的‘家叙事’”。', 'answers': ['厦门大学。'], 'length': 9593, 'dataset': 'multifieldqa_zh', 'language': 'zh', 'all_classes': None, '_id': '5b1b8e937b83c3ff9b75ac386fae9c4575c4b9f26a4fbdad'}\n",
      "dict_keys(['input', 'context', 'answers', 'length', 'dataset', 'language', 'all_classes', '_id'])\n",
      "全国美国文学研究会的第十八届年会在哪所大学举办的？\n",
      "['厦门大学。']\n",
      "9593\n",
      "全国美国文学研究会\n",
      "受秘书处委托，由我向美文会会员单位的各位代表简单汇报一下全国美国文学研究会自上届（第十七届）年会召开以来所做的工作。美文会秘书处刚刚完成了教育部社团办“关于在教育部主管社会组织中开展调研工作的通知”中要求提交的“全国美国文学研究会调研报告”（2016年11月），主要内容4项：我想就把我们提交的“调研报告”中1、2两部分中的部分内容，作为我向大会汇报的“全国美国文学研究会2014-2016年工作总结”的内容。\n",
      "1、研究会现状和基本情况\n",
      "美文会现有会员单位127个（不招收个人会员），包括国内主要985与211高校，以及中国社科院等科研单位和知名出版社。会长单位是南京大学，副会长单位是南京大学，中国社会科学院，北京外国语大学，北京大学，复旦大学，山东大学，秘书处设在南京大学外国语学院，秘书长、副秘书长是南京大学赵文书、何宁。美文会正式成立于1979年7月，是我国改革开放后成立最早的高校外国文学研究机构。1992年8月18日在民政部正式注册登记，获颁《中华人民共和国社会团体登记证》。美文会挂靠南京大学，财务由南京大学财务处负责，接受南京大学审计处审计，按民政部要求，每年参加年检，年检结果均为“通过”。\n",
      "美文会秘书处聘有专职秘书，工作人员7人，包括会长，副会长，秘书长，副秘书长，常务理事等。美文会设有党小组，隶属外国语学院英语系党支部，由会长任党小组长，成员包括副会长、常务理事、副秘书长、以及参加秘书处工作的青年教师与博士生。美文会发行《全国美国文学研究会通讯》（CASAL Newsletter），现已刊出33期。美文会每年轮流召开年会和专题研讨会，迄今已经举办17届年会和11届专题研讨会。\n",
      "2、近两年主要工作和取得的成效\n",
      "1）上届年会。美文会第十七届年会于2014年10月24日至26日在中国人民大学苏州校区举行，由中国人民大学外国语学院承办。来自全国28个省市自治区175所高等院校、研究所、出版社的348名正式代表参加了该次年会。年会的主题是“全球化语境中的美国文学研究：理论与实践”，收到论文全文164篇，摘要273篇。会议期间，全国美国文学研究会第七届理事会召开第三次会议。会议讨论通过了增补美文会副会长、常务理事、理事、会员单位事宜。会议再次明确，两期不缴纳会费的单位视为自动退出。理事和常务理事连续两次无故不参加理事会会议自动取消理事和常务理事。\n",
      "2、上届专题研讨会。美文会第十一届专题研讨会于2015年10月23至25日在徐州江苏师范大学举行，由江苏师大外国语学院承办。专题研讨会的主题是“美国文学中的城市”。来自全国21个省市自治区125所高等院校、研究所、出版社的88名正式代表参加了本次研讨会。收到论文全文54篇，论文摘要73篇。会议期间，美文会召开第七届理事会第三次会议，讨论通过了美文会秘书处的提议，增补何宁为理事兼任副秘书长，提请本届年会的理事会确认。\n",
      "3、业务活动。1）继续举办“全国美国文学研究会学术成果奖”评选。美文会设立此奖项，是为了促进我国美国文学研究的繁荣与发展，每5年评选一次，迄今已经评选3次。第三届成果奖评选出“优秀专著奖”14项，在2015年10月公示，“优秀论文奖”9项，“优秀教材奖”3项，“优秀译作奖”1项。该活动不收取任何费用。2）第十七届美国戏剧研究年会。由南京师范大学外国语学院承办，2015年7月21-22日在南京举办，主题是“20-21世纪之交美国戏剧研究”。\n",
      "4、年检情况。美文会接受业务主管单位教育部的业务指导和社团管理机关民政部社团的监督管理，执行《民间非营利组织会计制度》，接受南京大学财务处、审计处的管理和督查，接受“江苏兴瑞会计师事务所有限公司”财务审计，结果报教育部、民政部。2015年3月进行年检，编制2015年度美文会工作报告书。8月民政部“中国社会组织网”公布年检结果：“合格”。\n",
      "2016年11月25日晚，全国美国文学研究会召开理事会，讨论了如下事项。\n",
      "会议申办：\n",
      "1. 19届年会（2018，浙江大学）和第12届专题研讨会（2017，河海大学），主题尚没有最终确定。\n",
      "2. 哈尔滨工业大学申办第20届年会（2020）\n",
      "新申请理事单位：\n",
      "1. 中国矿业大学，推荐王丽明副教授担任理事\n",
      "2. 哈尔滨工业大学，推荐刘克东院长任理事\n",
      "3. 南京大学，推荐何宁（美文会副秘书长）任理事\n",
      "会员单位变更：\n",
      "1. 解放军国际关系学院按照相关要求退出全国美国文学研究会，因此不再常务理事单位，方成教授退出常务理事\n",
      "2. 对外经贸大学英语学院英美文学研究所长金冰接替孙建秋担任理事\n",
      "3. 中央民族大学外国语学院朱小琳接替郭英剑担任理事\n",
      "4. 厦门理工大学张跃军担任理事（原为中南大学常务理事）\n",
      "5. 上海外语教育出版社孙静接替汪义群担任理事\n",
      "6. 黑龙江大学推荐徐文培为常务理事\n",
      "美国族裔文学研究：空间拓展与界域重绘\n",
      "全国美国文学研究会第十八届年会（2016）纪要\n",
      "2016年11月25日至28日，全国美国文学研究会第十八届年会在厦门大学举行。本届年会由厦门大学外文学院承办，来自全国各地180余所高等院校、研究所、出版社的296位正式代表参加了会议。大会组委会共收到论文全文127篇、摘要371篇，与会代表围绕大会主题“美国族裔文学研究：空间拓展与界域重绘”（Ethnic Studies in US: Extending Interspace and Redefining Typology）展开了广泛而深入的研讨。\n",
      "11月25日晚，全国美国文学研究会召开常务理事和理事会，共有23位常务理事和理事出席，理事会主要讨论通过了以下议题：\n",
      "1. 确认2017年的专题研讨会由河海大学承办，河海大学外国语学院院长蔡斌教授在闭幕式作简单介绍。\n",
      "2. 确认2018年第十九届年会由浙江大学承办。\n",
      "3. 因政策变化，解放军国际关系学院退出美文会，方成教授不再担任常务理事。\n",
      "4. 增补黑龙江大学徐文培教授为常务理事。\n",
      "5. 增补哈尔滨工业大学（刘克东教授）、北京航空航天大学（田俊武教授）、中国矿业大学（王丽明副教授）、北京联合大学（黄宗英教授）为理事单位，山东大学李保杰教授、对外经济贸易大学金冰教授（接替孙建秋教授）、中央民族大学朱小琳教授（接替郭英剑教授）、上海外语教育出版社孙静（接替汪义群）为理事。\n",
      "6. 重新明确会员单位申请原则。美文会实行单位会议制，欢迎尚未加入协会的单位申请加入。申请方法和申请表格可以从美文会官网上下载。填写后加盖单位公章邮寄到协会秘书处。美文会秘书处收到入会申请并收到会员费之后即通报理事会并确认会员单位资格。\n",
      "7. 重新明确理事单位申请条件。第一，理事单位必须是正常缴纳会费的会员单位；第二，原则上需有英语语言文学硕士点；第三，符合以上条件单位可以申请成为美文会理事单位并推荐合适人选担任理事。\n",
      "8. 理事会决定，在美文会的年会和专题研讨会上评选会议优秀论文并颁发证书。其中，优秀论文仅在向会议提交的论文全文（未发表）中评选；作者所在单位须为美文会员单位，在向会议提交论文时，注明论文未经发表，并注明申请参加会议优秀论文评选；美文会常务理事以上（含）不参加申请。\n",
      "9. 关于本次年会优秀论文评选：已向会议提交未发表论文全文的会员单位参会代表，在12月15日前，向本会秘书处提交修改后的论文申请评选，本会将在寒假组织评选，在2017年3月公布评选结果并颁发证书。\n",
      "11月26日上午，本届年会开幕式在厦门大学科艺报告厅举行。厦门大学校长助理张建霖教授，外文学院张龙海院长，全国美国文学研究会会长朱刚教授、副会长盛宁教授、郭继德教授、杨仁敬教授、金莉教授、王守仁教授、张冲教授、申富英教授，秘书长赵文书教授及其他与会代表出席了开幕式。\n",
      "开幕式由外文学院副院长李美华教授主持。张建霖校长助理首先代表厦门大学对来自全国各地的与会者表示热烈欢迎，并对全国美国文学研究会第十八届年会的顺利召开表示衷心祝贺。外文学院张龙海院长代表承办方致欢迎辞，向与会者介绍了厦大外文学院的人才培养、学术研究等情况，以及年会的准备情况。全国美国文学研究会朱刚会长代表与会人员感谢厦门大学对本届年会的大力支持。朱会长简要回顾了美文会的历史和现状，并向与会代表汇报了研究会自第十七届年会以来的主要工作。最后，朱刚会长感谢全体参会代表及承办方对美文会工作的大力支持和对共同推动美国文学研究所做出的贡献，并对今后的工作提出了殷切希望。\n",
      "本届年会共分为大会发言、小组讨论、专题研讨（panel discussion）及研究生学术论坛四个部分。11月26日上午的大会发言分别由美文会副会长金莉教授和美文会前副会长、南京大学王守仁教授主持，共有5位代表发言。\n",
      "中国社科院外国文学研究所盛宁教授的发言题目是《对政治正确的文化批评的再审视》。盛宁教授指出，美国总统大选造成的国内民族分裂愈演愈烈，这一新国情使我国的族裔文学研究更具价值和意义。作为学者我们必须凸显自己的立场和价值判断，对少数族裔文学的审美价值要有清晰的认识。盛教授以第一代华裔作家代表汤婷婷和第二代华裔作家代表哈金为例，评析了两代作家迥异的“政治正确”书写策略。他认为，借助“政治正确”发音的族裔文学的审美价值会很快消失，我们应深刻反思非裔作家的代表――托尼・莫里森――的创作遗产。莫里森不只着眼于描写黑人苦难，更深入探索人性，将黑人作为“人性”的缩影进行刻画，这是她能够进入美国文学传统、流芳传世的重要原因。\n",
      "复旦大学外文学院张冲教授以《超越族裔：美国族裔文学研究的几点思考》为题，探讨我国当前族裔文学研究面临的困境及出路。张冲教授指出，国内族裔文学研究仍然面临研究角度单一与模仿、研究方法过于“理论导向”、文本“碎片化”释读等问题。他建议可从“族裔文学发展流变史”、“比较族裔文学史”以及“本土裔与中国文学文化比较”等维度，重新思考我国方兴未艾的族裔文学研究，族裔文学研究应努力超越族裔而回归文学，既要思考族裔文学的“族裔性”也需关注其“文学性”。\n",
      "在《再议作家的族裔身份问题：本质主义与自由选择》的发言中，上海外国语大学虞建华教授以斯图亚特・霍尔对“身份”的定义为出发点，对现有族裔身份的归置基准进行拷问。虞教授强调，在讨论族裔作家文化身份时，我们需聚焦常被忽视的身份的表演性和叙事性，应以社会建构理论为指导思路，走出本质主义，作家的族裔身份在全球化大势下的多元社会，应被看作一个动态、临时、杂糅的建构过程。\n",
      "南京大学英语系朱雪峰副教授的发言《重组芝加哥：拉图尔ANT理论视阈下的<克莱伯恩公园>》以社会学家布鲁诺・拉图尔的“行动者网络理论”为视角，从“流动的城市”、“行动者网络”、“蚂蚁视角与新现实主义”三个层面审视《克莱伯恩公园》中的芝加哥城市再现。朱教授认为，此剧在美国本土政治正确风潮中的接受悖论正在于它如实近距离描述了芝加哥城市地理在互动中流变的复杂性，其政治相关性在于它没有给出一个关于芝加哥社会的明晰解释或批评，而是通过不断追踪新问题联合来重组社会，以貌似传统的新现实主义风格体现了戏剧价值。\n",
      "厦门大学外文学院张龙海教授以《美国少数族裔文学研究在中国》为题，向大家勾勒了我国美国族裔文学研究的历史图景。张教授通过大量的文献研究和详细的数据，从研究的规模、研究队伍的状况、期刊报纸的刊登情况以及研究中出现的不平衡等方面详细探析美国少数族裔文学研究在中国的涌现和繁荣发展。\n",
      "11月26日下午，年会设立23个分会场进行小组讨论。代表们围绕“华裔文学研究新视野”、“亚裔文学研究新视野”、“非裔文学研究新视野”、 “犹太裔文学研究新视野”、“拉美裔文学研究新视野”、“印第安裔文学研究新视野”、“族裔文学与性别研究”、“族裔文学批评理论新动向”、“少数族裔与多元文化”、“族裔文学研究中的中国视角”、“美国文学理论研究与教学”、“美国现代派文学研究”、“早期美国文学研究”等议题，对美国族裔文学展开了多层次全方位的探讨。\n",
      "第一组（专题讨论：族裔成长小说研究）由方红、芮渝萍主持，发言人有方红（南京大学）“消声、言说与成长：《褐姑娘、褐砖房》研究”；侯金萍（华南农业大学）“华裔美国文学对成长小说的改写与创新”；芮渝萍（宁波大学）“美国华裔成长小说的特点”；谭岸青（暨南大学）“解读任碧莲《世界与小镇》的成长书写”；邹惠玲（江苏师范大学）“《飞逸》：在自省与融合之中成长”。\n",
      "第二组（华裔文学研究新视野之一）由刘永杰、戴鸿斌主持，发言人有黄明（商丘师范学院）“严歌苓小说《扶桑》对华人形象的颠覆”；霍盛亚（北京外国语大学）“华裔美国科幻作家刘宇昆小说的“复族裔化”倾向”；刘向辉（许昌学院）“谭恩美小说《喜福会》中的文学地图与民族记忆”；刘永杰（郑州大学）“‘秘密’的真相：《蝴蝶君》主人公断袖之谊探析”；史博（华北科技学院）“解读《折纸》中爱的主题”；孙坚（陕西师范大学）“新历史主义关照下的《中国佬》”；颜碧洪（福建师范大学福清分校）“论汤亭亭《中国佬》的后现代主义书写”。\n",
      "第三组（华裔文学研究新视野之二）由郭栖庆、金衡山主持，发言人有黄一畅（南京航空航天大学）“虚构的权威―《谁是爱尔兰人？》中的叙事伦理之辨”；季峥（重庆工商大学）“华裔美国作家入典原因探究”；金衡山（华东师范大学）“The Puzzling and Enlightening Racial Identity in Who’ s Irish？”；苏娉（中山大学）“论李翊云的非母语写作及其意义”；王芳（中央民族大学）“《无声告白》中的华裔精神生存困境探析”；王增红（厦门大学）“种族冒充、冒充叙事与混血族身份政治―威妮弗蕾德•伊顿新解”；姚红艳（武汉大学）“族群记忆、族群认同与身份建构―《接骨师之女》中的仪式书写”；周凌敏（南方医科大学）“以物为导向的本体论下的后人文主义―以《咸鱼女孩》为例”。\n",
      "第四组（族裔文学与性别研究之一）由王玉括、田俊武主持，发言人有方小莉（四川大学）“20世纪黑人女性小说叙述策略研究”；李蕊（南京大学）“论《他们眼望上苍》中珍妮的‘生成女性’特质”；毛艳华（浙江大学）“性别‘引用’视域下《秀拉》中女性主体的初现与重构”；隋红升（浙江大学）“汉斯伯里《太阳下的葡萄干》对美国男性气质的反思”；田俊武（北京航空航天大学）“回归之路―托尼•莫里森作品中的旅行叙事”；王玉括（南京邮电大学）“黑人女性主义文学批评述评”；杨艳春（哈尔滨石油学院）“生态女性主义视域下艾丽丝•沃克作品中女性族裔身份的自我认同”；朱海峰（东北师范大学）“父权、女权、后女权―论《钢琴课》中黑人的种族出路”。\n",
      "第五组（族裔文学与性别研究之二）由张跃军主持，发言人有董秋芳（广东农工商职业技术学院）“美国华裔女性主体身份流变―以华裔女作家英语创作为例”；刘兮颖（华中师范大学）“《卢布林的魔术师》中雅夏的身份危机与伦理选择”；杨静（广东外语外贸大学）“全球化时代的跨国婚姻：《追寻亚裔女性》”；姚丽梅（佳木斯大学）“论邝丽莎在《雪花秘扇》中的女性主义身份伦理观”；张跃军（厦门理工学院）“‘温和的女性主义’：华裔美国诗人陈美玲诗歌解读”；朱骅（上海海洋大学）“跨国主义的美国族裔文学建构”。\n",
      "第六组（犹太裔文学研究新视野）由刘文松主持，发言人有高莉敏（上海立信会计金融学院）“《末世之城》：大屠杀的历史记忆”；胡选恩（陕西师范大学）“E.L.多克托罗《大进军》中的历史阐释模式”；孔伟（北京外国语大学）“俄国犹太人的‘应许之地’―新移民叙事中的‘发声’策略研究”；刘文松（厦门大学）“美国犹太知识分子小说探秘”；孙璐（上海外国语大学）“菲利普•罗斯《美国牧歌》中的美国民族神话及其当代启示”；张国庆（中国人民大学）“《人性的污秽》的后人道主义解读”；赵永健（浙江工商大学）“国外美国犹太戏剧研究评述”。\n",
      "第七组（美国后现代派文学研究之一）由陈世丹、刘雪岚主持，发言人有杨仁敬（厦门大学）“略论《时间》与《达洛威夫人》的互文性”；陈世丹（中国人民大学）“后现代文学伦理学批评要义”；曾艳钰（湖南科技大学）“‘流动的爱国主义盛宴’―评美国后现代战争小说”；谷红丽（华南师范大学）“后现代主义历史叙事”；刘雪岚（社会科学院外国文学研究所）“从‘加州三部曲’看托马斯•品钦的后现代城市书写”；方凡（浙江大学）“论威廉•加斯笔下的图像与文字”；王祖友（泰州学院）“后人道主义与人道主义辨析”；陈奔（厦门大学）“美国研究背景下的后现代主义文学研究”；范小玫（厦门大学外）“德里罗小说中的全球化”。\n",
      "第八组（美国后现代派文学研究之二）由吴泽庆、陈俊松主持，发言人有陈俊松（华东师范大学）“《地下世界》：冷战阴云的文化记忆与后现代恐怖叙事”；许希夷（南京大学）“福尔‘后9/11’小说《特别响，非常近》中的历史叙事”；史菊鸿（兰州大学）“一个城市，两幅画面――库切和詹姆斯对伦敦的不同文学再现”；吴泽庆（中央民族大学）“‘恶魔的诅咒’―欧茨的《被诅咒的》中历史书写”；姚本标（广西师范学院）“《白噪音》的‘风险社会’表征”；栾天宇（南京大学）“《赛姆勒先生的行星》中的记忆伦理与美国20世纪60年代”。\n",
      "第九组（美国后现代派文学研究之三）由甘文平、杨纪平主持，发言人有甘文平（武汉理工大学）“米歇尔•福柯、共同体、美国越战文学”；崔永光（大连海洋大学）“世界文学史视域中的纳博科夫形象及其创作密码”；范湘萍（上海政法学院）“论‘9.11文学’结构主义叙事中的空间与政治”；林莉（东北师范大学）“论小说《恶棍来访》的空间叙事策略”；刘丹（大连外国语大学）“融合与分裂：《地下世界》中的种族冲突与文化政治”；王程辉（湖南科技大学）“纳博科夫《国王、王后和杰克》与福楼拜《包法利夫人》的互文性”；杨纪平、胡燕（北京邮电大学）“《X战警：第一战》中的族裔观”；张芳芳（上海电力学院）“论纳博科夫小说《普宁》中‘坐错车’的隐喻与流亡主题”；张蓝予（中央民族大学）“文明对话与身份认同：评《恐怖分子》的身份观念”。\n",
      "第十组（拉美裔文学研究新视野）由李保杰、李毅峰主持，发言人有李保杰（山东大学）“当历史的重负成为过去―《古巴之王》中的‘反流亡’书写”；李毅峰（天津商业大学）“桑德拉•西斯内罗斯对女性原型形象的重新阐释”；乔玲玲（山西大同大学）“芒果街上的奇卡纳游荡者”；涂沙丽（中南民族大学）“论《石化鹿》中的奇卡娜形象”；王绵绵（浙江传媒学院）“加勒比裔美国移民女作家的空间意识及空间策略”。\n",
      "第十一组（美国文学理论研究与教学）由郭建辉、刘春芳主持，发言人有陈�Q（中央民族大学）“论当代反本质主义文学理论的发生因缘与中国进程”；郭建辉（四川外国语大学期刊社）“英美文学教学与审美教育”；焦敏（广东外语外贸大学）“人文主义与戏剧教学”；刘春芳（山东工商学院）“美国浪漫主义文学中的平民思想”；马特（中央财经大学）“文学批评的空间转向：空间批评的新动向”；许玉军（集美大学）“东方启蒙：西方的‘东方主义’话语”。\n",
      "第十二组（族裔文学批评理论新动向）由胡铁生、郭英剑主持，发言人有胡铁生（吉林大学）“美国少数族裔文学的演进”；郭英剑（中国人民大学）“2015美国文学：种族，还是种族问题”；洪琪（湖北第二师范学院）“美国华裔戏剧的创伤叙事”；任虎军（四川外国语大学）“性别视阈下新世纪中国的美国族裔小说研究”；王斐（集美大学）“追寻都会中的空间正义：美国非裔城市叙事嬗变初探”。\n",
      "第十三组（美国现代派文学研究之一）由黄宗英、王跃洪主持，发言人有陈秋红（青岛大学）“亨利•詹姆斯后期小说的进化叙述”；陈喜华（湘潭大学）“菲茨杰拉德的服饰书写与爵士时代美国文化”；黄宗英（北京联合大学）“‘其城/其人，一种身份’：读威廉斯的《帕特森》”；蒋贤萍（西北师范大学）“表演的自我――再读《进入黑夜的漫长旅程》”；李晶（中南财经政法大学）“生存还是生活？：凯瑟《一个迷途的女人》的伦理选择”；陶久胜（南昌大学）“无意识的种族偏见――《上帝的儿女都有翅膀》的心理原型解读”；朱晓萍（贵州大学）“追逐无的欲望――《嘉莉妹妹》的拉康式解读”。\n",
      "第十四组（美国现代派文学研究之二）由李建波、朴玉主持，发言人有朴玉（吉林大学）“科伦•麦凯恩在《光明这一面》中的城市创伤叙事”；王晓丹（哈尔滨师范大学）“阶层流动的幻灭：《纹身女孩》中的社会身份”；王跃洪、郝天昕（上海理工大学）“福柯凝视理论视角下的亨利•詹姆斯《德莫福夫人》研究”；薛丽（北京师范大学）“《布拉迪默传奇》中矛盾的女性意识形态”；姚学丽（安徽大学）“映射美国南方的‘隐约轮廓’――析《干旱的九月》碎片化叙事”；张金良（天津外国语大学）“哈贝马斯有效沟通视域下《奥利安娜》中的交流困境分析”；张小平（扬州大学）“旅行•幻梦•混沌――论麦卡锡小说《骏马》中的‘奇异吸引子’”。\n",
      "第十五组（早期美国文学研究）由张和龙、金冰主持，发言人有金冰（对外经贸大学）“美国自然主义文学的进化叙事与伦理想像”；李晋（中南财经政法大学）“19世纪美国文学市场研究综述”；李敏（山东工商学院）“《红字》通奸案的法、罚与霍桑的‘疼痛’书写”；李方木（北京外国语大学）“爱的伪装：《献给爱米丽的玫瑰》中的罗曼司及其多义性”；戚涛（安徽大学）“多数暴政下的碎片――梅尔维尔的价值困惑与身份建构”；张和龙（上海外国语大学）“中国杰克•伦敦研究中的话语模式及其历史嬗变”。\n",
      "第十六组（非裔文学研究新视野之一）由林元富主持，发言人有陈红（广东外语外贸大学）“‘所有的故事都是真的’―评怀德曼的编史元小说《法农》”；甘婷（集美大学）“第三空间理论视阈下《中间通道》的空间建构”；林元富（福建师范大学）“当代非裔美国涉奴题材小说的历史传承”；刘锦丽（湖北科技学院）“种族歧视下的身份困惑―论切斯纳特小说中的混血儿”；龙跃（湖南师范大学）“兰斯顿•休斯诗歌中的‘黑人性’”；吕春媚（大连外国语大学）“黑白的空间对峙――解读《莱尼大妈的黑臀舞》中的社会空间”；王予霞（集美大学）“美国黑人左翼文学消长的历史启示”；修树新（东北师范大学外国语学院）“论特瑞•麦克米兰小说中爱的主题”；张健然（四川外国语大学）“《他们眼望上苍》中原始性与现代性的背离与融合”。\n",
      "第十七组（非裔文学研究新视野之二）由徐文培、杜志卿主持，发言人有杜志卿（华侨大学外国语学院）“从霍妮的精神分析理论看阿契贝笔下的伊祖鲁”；蒯冲（荆楚理工学院）“非裔美国人的身份缺失与身份认同――以《阳光下的葡萄干》为例”；李美芹（浙江工商大学）“论埃里森‘文学爵士乐’美学中表达的种族政治思想”；李云瑾（华北科技学院）“论托妮•莫里森《宣叙》的含混性”；马粉英（西北师范大学）“《最蓝的眼睛》中克劳迪娅拆解行为的后殖民叙事”；唐莹（大连外国语大学）“从‘挪亚的诅咒’到非洲主义―对罗宾逊种族书写的反思”；徐文培（黑龙江大学）“《所罗门之歌》与奴隶叙事文学”；张宏薇（东北师范大学）“莫里森早晚期两部小说中‘儿童创伤’主题的对比分析”；朱小琳（中央民族大学）“悲莫悲兮伤永逝：以墓志为叙事策略的《宠儿》新解”。\n",
      "第十八组（亚裔文学研究新视野）由谷红丽、李汝成主持，发言人有李青霜（南京审计大学）“论戏剧《耻辱》中的穆斯林文化定势”；刘喜波（齐齐哈尔大学）“列斐伏尔的身体空间理论下的《灿烂千阳》解读”；李东风（盐城师范学院）“美国印度裔离散文学中的‘家叙事’”。\n"
     ]
    }
   ],
   "source": [
    "from langserve.client import RemoteRunnable\n",
    "import os\n",
    "import json\n",
    "\n",
    "def read_jsonl_files(folder_path):\n",
    "    # 检查文件夹路径是否存在\n",
    "\n",
    "    # 存储所有JSON对象的列表\n",
    "    json_objects = []\n",
    "\n",
    "    with open(folder_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 解析JSON对象并添加到列表中\n",
    "            json_objects.append(json.loads(line.strip()))\n",
    "\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = 'data/multifieldqa_zh.jsonl'\n",
    "\n",
    "# 读取JSONL文件\n",
    "json_objects = read_jsonl_files(folder_path)\n",
    "\n",
    "# 打印读取的JSON对象\n",
    "for obj in json_objects:\n",
    "    print(obj)\n",
    "    print(obj.keys())\n",
    "    print(obj['input'])\n",
    "    print(obj['answers'])\n",
    "    print(obj['length'])\n",
    "    print(obj['context'])\n",
    "    break\n",
    "# rag_app_ollama = RemoteRunnable(\"http://127.0.0.1:8000/rag-ollama-multi-query\")\n",
    "\n",
    "# rag_app_ollama.invoke(\"What are the different types of agent memory?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['South West Ultras fan club.']\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 35\u001B[0m\n\u001B[1;32m     32\u001B[0m all_splits \u001B[38;5;241m=\u001B[39m text_splitter\u001B[38;5;241m.\u001B[39msplit_text(json_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Vectorize the text and store it in Chroma\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m \u001B[43mChroma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_splits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrag-private\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mOllamaEmbeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m retriever \u001B[38;5;241m=\u001B[39m vectorstore\u001B[38;5;241m.\u001B[39mas_retriever()\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# Set up RAG model\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:736\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatch_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_batches\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m create_batches(\n\u001B[1;32m    731\u001B[0m         api\u001B[38;5;241m=\u001B[39mchroma_collection\u001B[38;5;241m.\u001B[39m_client,\n\u001B[1;32m    732\u001B[0m         ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[1;32m    733\u001B[0m         metadatas\u001B[38;5;241m=\u001B[39mmetadatas,\n\u001B[1;32m    734\u001B[0m         documents\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[1;32m    735\u001B[0m     ):\n\u001B[0;32m--> 736\u001B[0m         \u001B[43mchroma_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[43m            \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    740\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    741\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    742\u001B[0m     chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(texts\u001B[38;5;241m=\u001B[39mtexts, metadatas\u001B[38;5;241m=\u001B[39mmetadatas, ids\u001B[38;5;241m=\u001B[39mids)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:275\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(texts)\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 275\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metadatas:\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;66;03m# fill metadatas with empty dicts if somebody\u001B[39;00m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;66;03m# did not specify metadata for all texts\u001B[39;00m\n\u001B[1;32m    279\u001B[0m     length_diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(texts) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(metadatas)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:211\u001B[0m, in \u001B[0;36mOllamaEmbeddings.embed_documents\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m \n\u001B[1;32m    204\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;124;03m    List of embeddings, one for each text.\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    210\u001B[0m instruction_pairs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_instruction\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts]\n\u001B[0;32m--> 211\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstruction_pairs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:199\u001B[0m, in \u001B[0;36mOllamaEmbeddings._embed\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_emb_response(prompt) \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m iter_]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:199\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_emb_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m iter_]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:164\u001B[0m, in \u001B[0;36mOllamaEmbeddings._process_emb_response\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    158\u001B[0m headers \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders \u001B[38;5;129;01mor\u001B[39;00m {}),\n\u001B[1;32m    161\u001B[0m }\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/api/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_default_params\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError raised by inference endpoint: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/requests/api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[0;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/requests/adapters.py:486\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    483\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    787\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 790\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    806\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/urllib3/connection.py:461\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 461\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/http/client.py:1377\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1377\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/http/client.py:320\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/http/client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from splitter.DynamicSizeFixedStepSplitter import DynamicSizeFixedStepSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "output_folder = \"/Users/bifenglin/Code/SW-RAG/packages/rag-ollama-multi-query/data/multifieldqa_en_bench/multifieldqa_en_answer_DFS_512_64\"\n",
    "input_folder = \"/Users/bifenglin/Code/SW-RAG/packages/rag-ollama-multi-query/data/multifieldqa_en\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # 创建文件夹，如果已存在则不会报错\n",
    "\n",
    "for i in range(0, len(os.listdir(input_folder))):\n",
    "    print(i)\n",
    "    input_file = f\"{input_folder}/output_{i}.json\"\n",
    "    output_file = f\"{output_folder}/aoutput_{i}.json\"\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "        # Create database client\n",
    "        client = chromadb.Client()\n",
    "        if i != 0:\n",
    "            client.delete_collection(\"rag-private\")\n",
    "\n",
    "        # Split text\n",
    "        text_splitter = DynamicSizeFixedStepSplitter(chunk_size=512, step_window=64)\n",
    "        all_splits = text_splitter.split_text(json_data[\"context\"])\n",
    "\n",
    "        # Vectorize the text and store it in Chroma\n",
    "        vectorstore = Chroma.from_texts(\n",
    "            texts=all_splits,\n",
    "            collection_name=\"rag-private\",\n",
    "            embedding=OllamaEmbeddings(),\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "\n",
    "        # Set up RAG model\n",
    "        prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "\n",
    "        model = ChatOllama()\n",
    "        chain = (\n",
    "                RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "                | prompt\n",
    "                | model\n",
    "                | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Add type to input\n",
    "        class Question(BaseModel):\n",
    "            __root__: str\n",
    "\n",
    "        chain = chain.with_types(input_type=Question)\n",
    "\n",
    "        # Run the chained process and save the results to the output file\n",
    "        output = {}\n",
    "        try:\n",
    "            output[\"answer\"] = chain.invoke(json_data[\"input\"])\n",
    "            print(json_data[\"answers\"])\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(output, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:32:42.027871Z",
     "start_time": "2024-05-18T06:29:57.257084Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "graph",
   "language": "python",
   "display_name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
